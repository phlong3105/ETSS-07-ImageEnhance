{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52dd366d-8533-4092-855c-7978f7d396ba",
   "metadata": {},
   "source": [
    "import sys\n",
    "import torch\n",
    "print(f\"Python version: {sys.version}, {sys.version_info} \")\n",
    "print(f\"Pytorch version: {torch.__version__} \")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c455423-ff75-4bd1-9b49-6e9826440c58",
   "metadata": {},
   "source": [
    "!nvidia-smi"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c9bdd45-f5fd-4865-b060-4cca4333ce65",
   "metadata": {},
   "source": [
    "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57cea8f5-72bb-453e-a97a-af59a11231de",
   "metadata": {},
   "source": [
    "# export ONNX model for onnxruntime\n",
    "!python export.py --weights ./yolov7-tiny.pt --grid --end2end --simplify \\\n",
    "    --topk-all 100 --iou-thres 0.65 --conf-thres 0.35 \\\n",
    "    --img-size 640 640 \\\n",
    "    --dynamic-batch \\\n",
    "    --max-wh 7680\n",
    "!ls"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ec4c01e-dac9-417e-b4cf-7c6440e274e9",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict,namedtuple"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06a9a121-40a2-4eb6-8a79-94894a01915a",
   "metadata": {},
   "source": [
    "cuda = True\n",
    "w = \"yolov7-tiny.onnx\"\n",
    "imgList = [cv2.imread('inference/images/horses.jpg'),\n",
    "           cv2.imread('inference/images/bus.jpg'),\n",
    "           cv2.imread('inference/images/zidane.jpg'),\n",
    "           cv2.imread('inference/images/image1.jpg'),\n",
    "           cv2.imread('inference/images/image2.jpg'),\n",
    "           cv2.imread('inference/images/image3.jpg')]\n",
    "imgList*=6\n",
    "imgList = imgList[:32]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "007a7721-c49d-4713-94c6-4a57790acabd",
   "metadata": {},
   "source": [
    "providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if cuda else ['CPUExecutionProvider']\n",
    "session = ort.InferenceSession(w, providers=providers)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdf1c66b-37bf-4c94-9005-2338331cf73d",
   "metadata": {},
   "source": [
    "names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', \n",
    "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', \n",
    "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', \n",
    "         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', \n",
    "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', \n",
    "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', \n",
    "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', \n",
    "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', \n",
    "         'hair drier', 'toothbrush']\n",
    "colors = {name:[random.randint(0, 255) for _ in range(3)] for i,name in enumerate(names)}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf8215aa-918e-4c5a-b67b-70b5c3f1ba15",
   "metadata": {},
   "source": [
    "def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleup=True, stride=32):\n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = im.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return im, r, (dw, dh)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9ce7a13-31b8-4a35-bd8d-4f0debd46480",
   "metadata": {},
   "source": [
    "origin_RGB = []\n",
    "resize_data = []\n",
    "for img in imgList:\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  origin_RGB.append(img)\n",
    "  image = img.copy()\n",
    "  image, ratio, dwdh = letterbox(image, auto=False)\n",
    "  image = image.transpose((2, 0, 1))\n",
    "  image = np.expand_dims(image, 0)\n",
    "  image = np.ascontiguousarray(image)\n",
    "  im = image.astype(np.float32)\n",
    "  resize_data.append((im,ratio,dwdh))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1cae709-f145-4c63-b846-8edd6716f06b",
   "metadata": {},
   "source": [
    "np_batch = np.concatenate([data[0] for data in resize_data])\n",
    "np_batch.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c382a4d2-b37a-40be-9618-653419319fde",
   "metadata": {},
   "source": [
    "outname = [i.name for i in session.get_outputs()]\n",
    "outname"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b448209b-3b92-4a48-9a55-134590e717d5",
   "metadata": {},
   "source": [
    "inname = [i.name for i in session.get_inputs()]\n",
    "inname"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef8bc01f-a7c6-47e0-93ed-42f41f631fee",
   "metadata": {},
   "source": [
    "# batch 1 infer\n",
    "im = np.ascontiguousarray(np_batch[0:1,...]/255)\n",
    "out = session.run(outname,{'images':im})\n",
    "out"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0376a85-ec36-41d3-9067-ec5a8ec5a231",
   "metadata": {},
   "source": [
    "# batch 4 infer\n",
    "im = np.ascontiguousarray(np_batch[0:4,...]/255)\n",
    "out = session.run(outname,{'images':im})\n",
    "out"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0a50aee-fa52-4b6e-aa92-bbb1f12d5652",
   "metadata": {},
   "source": [
    "# batch 6 infer\n",
    "im = np.ascontiguousarray(np_batch[0:6,...]/255)\n",
    "out = session.run(outname,{'images':im})\n",
    "out"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a72d2fd-14dd-42cf-b807-3e8a82b971d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# batch 32 infer\n",
    "im = np.ascontiguousarray(np_batch/255)\n",
    "out = session.run(outname,{'images':im})[0]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3ca9301-ba52-4a8c-9ae0-55b28be8a904",
   "metadata": {},
   "source": [
    "for i,(batch_id,x0,y0,x1,y1,cls_id,score) in enumerate(out):\n",
    "    if batch_id >= 6:\n",
    "        break\n",
    "    image = origin_RGB[int(batch_id)]\n",
    "    ratio,dwdh = resize_data[int(batch_id)][1:]\n",
    "    box = np.array([x0,y0,x1,y1])\n",
    "    box -= np.array(dwdh*2)\n",
    "    box /= ratio\n",
    "    box = box.round().astype(np.int32).tolist()\n",
    "    cls_id = int(cls_id)\n",
    "    score = round(float(score),3)\n",
    "    name = names[cls_id]\n",
    "    color = colors[name]\n",
    "    name += ' '+str(score)\n",
    "    cv2.rectangle(image,box[:2],box[2:],color,2)\n",
    "    cv2.putText(image,name,(box[0], box[1] - 2),cv2.FONT_HERSHEY_SIMPLEX,0.75,[225, 255, 255],thickness=2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff5ce6a4-4fd9-4804-9afa-e8e8a3e20b41",
   "metadata": {},
   "source": [
    "Image.fromarray(origin_RGB[0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d13ed2df-ceb8-46c8-8bfc-aa7ff3750f03",
   "metadata": {},
   "source": [
    "Image.fromarray(origin_RGB[1])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4449198-3c2b-41d6-9a23-de7accf73d82",
   "metadata": {},
   "source": [
    "Image.fromarray(origin_RGB[2])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4faf6e6e-afb5-4c97-82c3-aeffdc9aba9e",
   "metadata": {},
   "source": [
    "Image.fromarray(origin_RGB[3])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27485468-2e69-4aaf-8089-ba0134a1b26f",
   "metadata": {},
   "source": [
    "Image.fromarray(origin_RGB[4])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef743cc3-7ae9-495c-ab24-2ac25967ec5c",
   "metadata": {},
   "source": [
    "Image.fromarray(origin_RGB[5])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dad466-7aa2-4ba4-81f1-0d8f57268081",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch] *",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
