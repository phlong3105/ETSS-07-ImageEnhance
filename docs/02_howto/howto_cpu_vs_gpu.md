# How to choose: CPU vs GPU

Choosing the right device (CPU or GPU) for each step in a vision deep learning pipeline can greatly improve performance and resource efficiency.

---

## Task-by-Task Device Breakdown

| Task                                          | Best Device      | Reason                                                                 |
|-----------------------------------------------|------------------|------------------------------------------------------------------------|
| ğŸ”„ Image Loading (PIL, OpenCV)                | **CPU**          | Lightweight I/O; no benefit from GPU                                   |
| ğŸ§¹ Preprocessing (resize, crop, etc.)         | **CPU**          | Simple transforms are efficient on CPU                                 |
| ğŸ“¦ Data Augmentation (torchvision transforms) | **CPU**          | Basic augmentations are fast on CPU                                    |
| ğŸ“¦ Data Augmentation (batch, heavy transforms)| **GPU** (optional)| If using `kornia` or `transforms.v2`, GPU helps with heavy ops         |
| ğŸ“¤ DataLoader (batching, shuffling)           | **CPU** + workers| Use `num_workers > 0` for parallel loading                             |
| ğŸ”„ ToTensor & Normalize                       | **CPU**          | Lightweight and usually part of preprocessing                          |
| ğŸš€ Model Forward Pass (inference/training)    | **GPU**          | Convolutions, attention, etc. are much faster on GPU                   |
| ğŸ¯ Loss Calculation                           | **GPU**          | Small, but should be on same device as model output                    |
| ğŸ” Backpropagation                            | **GPU**          | Compute-intensive, best on GPU                                         |
| ğŸ“‰ Evaluation (model.eval())                  | **GPU** or CPU   | GPU for large batches, CPU is fine for small models/batches            |
| ğŸ’¾ Saving/Loading Models                      | **CPU or GPU**   | File I/O, but model must be moved to correct device                    |
| ğŸ–¼ï¸ Visualization (e.g., matplotlib)          | **CPU**          | Rendering and plotting work on CPU; move tensors if needed             |

## Best Practices

- Preprocessing & augmentations â†’ **CPU**
- Model + training/inference â†’ **GPU**
- Use `pin_memory=True` in DataLoader when training on GPU
- Move data to GPU **after** loading and preprocessing

## Efficient Workflow Summary

```text
[Disk (CPU)] â†’ Load image
        â†“
  Preprocess & Augment (CPU)
        â†“
   DataLoader (CPU + workers)
        â†“
    .to(device='cuda')
        â†“
 Forward Pass + Loss + Backprop (GPU)
